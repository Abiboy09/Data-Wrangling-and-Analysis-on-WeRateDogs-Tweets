{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wrangling Reports on\n",
    "##  WeRateDogs Twitter Data Project\n",
    "\n",
    "\n",
    "#### Wrangling processes:  \n",
    "> ▪Gathering Data  \n",
    "> ▪Assessing Data  \n",
    "> ▪Cleaning Data \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### The Data project process included:\n",
    "\n",
    "> ▪Gathering Data  \n",
    "> ▪Assessing Data  \n",
    "> ▪Cleaning Data \n",
    "> •Storing, analyzing and visualizing your wrangled data  \n",
    "> •Reporting on the data wrangling efforts and data analyse and\n",
    "> visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<u>Data Gathering Stage:</u>**\n",
    "\n",
    "> My Data was gathered sources:\n",
    ">\n",
    "> •**The WeRateDogs Twitter archive**. \n",
    ">  The twitter_archive_enhanced.csv file\n",
    "> was provided to me by the Udacity and it was downloaded to my workstation. The file contains\n",
    "> tweet data such as; retweeted_status_id, timestamp, tweet ID, rating_numerator, etc.\n",
    ">\n",
    "> •**The tweet image predictions**: i.e., what breed of dog (or other object,\n",
    ">  animal, etc.) is presented in each tweet according to a neural network.\n",
    ">  The image_predictions.tsv is hosted on Udacity's servers and it was \n",
    ">  downloaded programmatically using the requests library  via this link [image-predictions/image-predictions.tsv](https://d17h27t6h515a5.cloudfront.net/topher/2017/August/599fd2ad_image-predictions/image-predictions.tsv)\n",
    ">\n",
    "> •Twitter API and Python's Tweepy library to gather each tweet's\n",
    "> retweet count and\n",
    "> favorite (\"like\") count at minimum, and any additional data I find\n",
    "> interesting. I stored each tweet's entire set of JSON data in a file called tweet_json.txt file\n",
    "\n",
    "**<u>Data Assessment Stage :</u>**\n",
    "\n",
    "> These are the following Quality issues I found and Tidiness was deployed\n",
    ">\n",
    "> **<u>Quality Issue:</u>**\n",
    ">\n",
    "> **‘twitter-archive-enhanced-2.csv’**:\n",
    ">\n",
    "> •Completeness:\n",
    ">\n",
    "> ▪missing data in the following columns:  \n",
    "> in_reply_to_status_id, in_reply_to_user_id, retweeted_status_id,\n",
    "> retweeted_status_user_id, retweeted_status_timestamp, expanded_urls.\n",
    "\n",
    "> •Validity:\n",
    "> ▪ dog names: some dogs have 'None' as a name, or 'a', or 'an.'\n",
    "> \n",
    "> ▪ This data-set includes retweets, which means there is duplicated\n",
    "> data (as a result, these columns will be empty: retweeted_status_id,\n",
    "> retweeted_status_user_id and retweeted_status_timestamp).\n",
    ">\n",
    "> •Accuracy:\n",
    "> ▪ retweeted_status_timestamp is also an object (the other\n",
    "> retweeted statuses are floats)  \n",
    "> ▪Time-stamp is an object\n",
    ">\n",
    "> •Consistency:  \n",
    "> ▪The Source column still has the HTML tags  \n",
    "> ▪rating_denominator should be a standard 10, but there are a\n",
    "\n",
    "\n",
    "> **‘image_predictions.tsv’:**\n",
    ">\n",
    "> •Validity:\n",
    ">\n",
    "> ▪p1, p2 and p3 columns have invalid data\n",
    ">\n",
    "> •Consistency:\n",
    ">\n",
    "> ▪p1, p2 and p3 columns aren't consistent when it comes to\n",
    "> capitalization: sometimes the dog breed listed is all lowercase,\n",
    "> sometimes it is written in Sentence Case.\n",
    "> \n",
    "> ▪In p1, p2 and p3 columns there is an underscore for multi-word dog breeds.\n",
    "\n",
    "> **‘tweet_json’:**\n",
    ">\n",
    "> •Completeness: Missing Some Data\n",
    "\n",
    "> **<u>Tidiness Issue</u>:**\n",
    ">\n",
    "> **‘twitter-archive-enhanced-2.csv’:**\n",
    ">\n",
    "> •The last four columns all relate to the same variable (dogoo,\n",
    "> floofer, pupper, puppo).\n",
    "\n",
    "> **‘image_predictions.tsv’:**\n",
    ">\n",
    "> •This data set is part of the same observational unit as the data in\n",
    "> the **‘**twitter-archive-enhanced-2.csv’ - one table with all basic\n",
    "> information about the dog ratings.\n",
    ">\n",
    "> **‘tweet_json’:**\n",
    ">\n",
    "> •This data set is also part of the same observational unit - one table\n",
    "> with all basic information about the dog ratings.\n",
    "\n",
    "**<u>Cleaning Data:</u>**\n",
    "\n",
    "> After the assessment, I cleaned the data through the following means:\n",
    ">\n",
    "> **<u>Define, Code and Test</u>**:\n",
    ">\n",
    "> •Merge the clean versions of archive, images, and twitter_counts_df\n",
    "> dataframes Correct the dog types.\n",
    "\n",
    "> •Create one column for the various dog types: doggo, floofer, pupper,\n",
    "> puppo \n",
    ">\n",
    "> • Remove columns no longer needed: in_reply_to_status_id,\n",
    "> in_reply_to_user_id, retweeted_status_id, retweeted_status_user_id,\n",
    "> and retweeted_status_timestamp.\n",
    ">\n",
    "> •Delete retweets.\n",
    ">\n",
    "> •Remove columns no longer needed.\n",
    ">\n",
    "> •Change tweet_id from an integer to a string.\n",
    ">\n",
    "> •Change the timestamp to correct datetime format.\n",
    ">\n",
    "> •Creating a new dog_types column using the image prediction data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Storing Data For the Project\n",
    "\n",
    "Now that my data is clean and ready for analysis, I saved the master table to *twitter_archive_master.csv*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
